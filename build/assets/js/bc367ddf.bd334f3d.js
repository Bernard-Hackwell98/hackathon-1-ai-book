"use strict";(globalThis.webpackChunkai_book_ros2_module=globalThis.webpackChunkai_book_ros2_module||[]).push([[630],{5680(e,t,a){a.d(t,{xA:()=>c,yg:()=>y});var i=a(6540);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter(function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable})),a.push.apply(a,i)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach(function(t){n(e,t,a[t])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach(function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))})}return e}function s(e,t){if(null==e)return{};var a,i,n=function(e,t){if(null==e)return{};var a,i,n={},o=Object.keys(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var l=i.createContext({}),p=function(e){var t=i.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},c=function(e){var t=p(e.components);return i.createElement(l.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},u=i.forwardRef(function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),u=p(a),y=n,g=u["".concat(l,".").concat(y)]||u[y]||m[y]||o;return a?i.createElement(g,r(r({ref:t},c),{},{components:a})):i.createElement(g,r({ref:t},c))});function y(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,r=new Array(o);r[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:n,r[1]=s;for(var p=2;p<o;p++)r[p]=a[p];return i.createElement.apply(null,r)}return i.createElement.apply(null,a)}u.displayName="MDXCreateElement"},7314(e,t,a){a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>p});var i=a(8168),n=(a(6540),a(5680));const o={},r="Assessment Methods for Physical AI Module",s={unversionedId:"modules/physical-ai/assessments",id:"modules/physical-ai/assessments",title:"Assessment Methods for Physical AI Module",description:"Chapter 1: Introduction to Physical AI",source:"@site/docs/modules/physical-ai/assessments.md",sourceDirName:"modules/physical-ai",slug:"/modules/physical-ai/assessments",permalink:"/hackathon-1-ai-book/modules/physical-ai/assessments",draft:!1,editUrl:"https://github.com/bernard-hackwell98/hackathon-1-ai-book/tree/main/docs/modules/physical-ai/assessments.md",tags:[],version:"current",frontMatter:{}},l={},p=[{value:"Chapter 1: Introduction to Physical AI",id:"chapter-1-introduction-to-physical-ai",level:2},{value:"Quiz Questions",id:"quiz-questions",level:3},{value:"Practical Demonstrations",id:"practical-demonstrations",level:3},{value:"Chapter 2: ROS 2 Vision Primitives",id:"chapter-2-ros-2-vision-primitives",level:2},{value:"Quiz Questions",id:"quiz-questions-1",level:3},{value:"Practical Demonstrations",id:"practical-demonstrations-1",level:3},{value:"Chapter 3: Perception-Action Systems",id:"chapter-3-perception-action-systems",level:2},{value:"Quiz Questions",id:"quiz-questions-2",level:3},{value:"Practical Demonstrations",id:"practical-demonstrations-2",level:3},{value:"Comprehensive Assessment",id:"comprehensive-assessment",level:2},{value:"Final Project",id:"final-project",level:3},{value:"Rubric",id:"rubric",level:3}],c={toc:p};function m({components:e,...t}){return(0,n.yg)("wrapper",(0,i.A)({},c,t,{components:e,mdxType:"MDXLayout"}),(0,n.yg)("h1",{id:"assessment-methods-for-physical-ai-module"},"Assessment Methods for Physical AI Module"),(0,n.yg)("h2",{id:"chapter-1-introduction-to-physical-ai"},"Chapter 1: Introduction to Physical AI"),(0,n.yg)("h3",{id:"quiz-questions"},"Quiz Questions"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"What is the primary characteristic that distinguishes Physical AI from traditional AI?"),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"a) Use of neural networks"),(0,n.yg)("li",{parentName:"ul"},"b) Integration with physical systems through perception-action loops"),(0,n.yg)("li",{parentName:"ul"},"c) Ability to process natural language"),(0,n.yg)("li",{parentName:"ul"},"d) Superior computational power"))),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"Which of the following is NOT a key characteristic of Physical AI?"),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"a) Embodiment"),(0,n.yg)("li",{parentName:"ul"},"b) Real-time processing"),(0,n.yg)("li",{parentName:"ul"},"c) Isolation from the environment"),(0,n.yg)("li",{parentName:"ul"},"d) Uncertainty management"))),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"What does the perception-action loop consist of?"),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"a) Input, processing, output"),(0,n.yg)("li",{parentName:"ul"},"b) Perception, cognition, action, feedback"),(0,n.yg)("li",{parentName:"ul"},"c) Sensing, storing, retrieving, acting"),(0,n.yg)("li",{parentName:"ul"},"d) Detection, classification, prediction, execution")))),(0,n.yg)("h3",{id:"practical-demonstrations"},"Practical Demonstrations"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"Explain the concept of embodied cognition with a real-world example."),(0,n.yg)("li",{parentName:"ol"},"Describe how computer vision enables robot perception in a specific application."),(0,n.yg)("li",{parentName:"ol"},"Identify three integration challenges between vision and control systems.")),(0,n.yg)("h2",{id:"chapter-2-ros-2-vision-primitives"},"Chapter 2: ROS 2 Vision Primitives"),(0,n.yg)("h3",{id:"quiz-questions-1"},"Quiz Questions"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"Which ROS 2 message type is commonly used to represent images?"),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"a) sensor_msgs/Camera"),(0,n.yg)("li",{parentName:"ul"},"b) sensor_msgs/Image"),(0,n.yg)("li",{parentName:"ul"},"c) vision_msgs/Image"),(0,n.yg)("li",{parentName:"ul"},"d) geometry_msgs/Image"))),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"What is the purpose of cv_bridge in ROS 2 vision applications?"),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"a) To compress images for transmission"),(0,n.yg)("li",{parentName:"ul"},"b) To convert between ROS Image messages and OpenCV formats"),(0,n.yg)("li",{parentName:"ul"},"c) To calibrate cameras"),(0,n.yg)("li",{parentName:"ul"},"d) To synchronize multiple cameras"))),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"Which of the following is NOT a transport method supported by image_transport?"),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"a) Raw"),(0,n.yg)("li",{parentName:"ul"},"b) Compressed"),(0,n.yg)("li",{parentName:"ul"},"c) Encrypted"),(0,n.yg)("li",{parentName:"ul"},"d) Theora")))),(0,n.yg)("h3",{id:"practical-demonstrations-1"},"Practical Demonstrations"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"Create an image publisher that reads from a camera and publishes to a ROS 2 topic."),(0,n.yg)("li",{parentName:"ol"},"Implement a simple image processing node that converts color images to grayscale."),(0,n.yg)("li",{parentName:"ol"},"Design a stereo vision system that estimates depth from two camera feeds.")),(0,n.yg)("h2",{id:"chapter-3-perception-action-systems"},"Chapter 3: Perception-Action Systems"),(0,n.yg)("h3",{id:"quiz-questions-2"},"Quiz Questions"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"What is the main difference between Position-Based Visual Servoing (PBVS) and Image-Based Visual Servoing (IBVS)?"),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"a) PBVS uses more computational resources"),(0,n.yg)("li",{parentName:"ul"},"b) PBVS estimates 3D pose while IBVS works directly with image features"),(0,n.yg)("li",{parentName:"ul"},"c) IBVS is only used for indoor applications"),(0,n.yg)("li",{parentName:"ul"},"d) PBVS is faster than IBVS"))),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"What does SLAM stand for in robotics?"),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"a) Simultaneous Localization and Mapping"),(0,n.yg)("li",{parentName:"ul"},"b) Systematic Localization and Mapping"),(0,n.yg)("li",{parentName:"ul"},"c) Simultaneous Learning and Mapping"),(0,n.yg)("li",{parentName:"ul"},"d) Systematic Learning and Mapping"))),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"Which sensor combination is commonly used for robust robot localization?"),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"a) Vision + GPS only"),(0,n.yg)("li",{parentName:"ul"},"b) Vision + IMU"),(0,n.yg)("li",{parentName:"ul"},"c) LIDAR + GPS only"),(0,n.yg)("li",{parentName:"ul"},"d) Sonar + Odometry only")))),(0,n.yg)("h3",{id:"practical-demonstrations-2"},"Practical Demonstrations"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"Implement a simple image-based visual servoing system that controls a robot to center a target object in the camera view."),(0,n.yg)("li",{parentName:"ol"},"Design a sensor fusion system that combines visual and IMU data for robot localization."),(0,n.yg)("li",{parentName:"ol"},"Research and compare different visual SLAM approaches for robotics applications.")),(0,n.yg)("h2",{id:"comprehensive-assessment"},"Comprehensive Assessment"),(0,n.yg)("h3",{id:"final-project"},"Final Project"),(0,n.yg)("p",null,"Students should complete a comprehensive project that integrates concepts from all three chapters:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"Design a vision-based robot system that performs a specific task"),(0,n.yg)("li",{parentName:"ol"},"Implement ROS 2 nodes that process visual information"),(0,n.yg)("li",{parentName:"ol"},"Create a perception-action loop that allows the robot to interact with its environment"),(0,n.yg)("li",{parentName:"ol"},"Document the design decisions and explain how the system handles real-world challenges"),(0,n.yg)("li",{parentName:"ol"},"Demonstrate the system in simulation or with a physical robot")),(0,n.yg)("h3",{id:"rubric"},"Rubric"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Technical Understanding (40%)"),": Demonstrates clear understanding of Physical AI concepts, vision processing, and perception-action loops"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Implementation Quality (30%)"),": Code is well-structured, follows best practices, and functions correctly"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Documentation (20%)"),": Clear explanations, proper use of comments, and well-structured documentation"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Creativity and Innovation (10%)"),": Creative approach to problem-solving and innovative use of Physical AI concepts")))}m.isMDXComponent=!0}}]);